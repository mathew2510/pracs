{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0bfe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Working Base : E:\\notes\\MSc IT\\Pract 6  using  win32\n",
      "--------------------------------\n",
      "DB created\n",
      "DB connected\n",
      "Vault created\n",
      "Vault connected\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Hub-Time\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time-Africa-Abidjan\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Satellite-Time-Africa-Abidjan\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time-Africa-Accra\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Satellite-Time-Africa-Accra\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time-Africa-Addis_Ababa\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Satellite-Time-Africa-Addis_Ababa\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time-Africa-Algiers\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Satellite-Time-Africa-Algiers\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time-Africa-Asmara\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Satellite-Time-Africa-Asmara\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time-Africa-Asmera\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Satellite-Time-Africa-Asmera\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Process-Time-Africa-Bamako\n",
      "Storing : E:\\notes\\MSc IT\\Pract 6/88-DV/datavault.db  Table: Satellite-Time-Africa-Bamako\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0512eec9c2d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mTimeZoneRow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTimeZoneLine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mTimeZoneFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeZoneFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTimeZoneRow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     TimeZoneFrameIndex = TimeZoneFrame.set_index(['IDZoneNumber'],\n\u001b[0;32m    102\u001b[0m                                                  inplace=False)\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7980\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7981\u001b[0m         return (\n\u001b[1;32m-> 7982\u001b[1;33m             concat(\n\u001b[0m\u001b[0;32m   7983\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7984\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[0;32m    521\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             )\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0m_is_uniform_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mblk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m_is_uniform_join_units\u001b[1;34m(join_units)\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;31m# unless we're an extension dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;31m# unless we're an extension dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mis_na\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mvalues_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0misna_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues_flat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_reindexed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mempty_dtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDtypeObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36misna_all\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchecker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mchecker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mINF_AS_NA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_isna_string_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minf_as_na\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# this is the NaT pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\app_data\\conda\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_string_dtype\u001b[1;34m(values, dtype, inf_as_na)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnaobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pytz import timezone, all_timezones\n",
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "from pandas.io import sql\n",
    "import uuid\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "Base = r'E:\\notes\\MSc IT\\Pract 6'\n",
    "print('--------------------------------')\n",
    "print('Working Base :', Base, ' using ', sys.platform)\n",
    "print('--------------------------------')\n",
    "\n",
    "InputFileName = 'playstore-analysis.csv'\n",
    "OutputFileName = 'playstore-analysis_updated.csv'\n",
    "Company = 'Valia'\n",
    "\n",
    "sDataBaseDir = Base + '/' + Company + '/03-Process/SQLite'\n",
    "if not os.path.exists(sDataBaseDir):\n",
    "    os.makedirs(sDataBaseDir)\n",
    "print('DB created')\n",
    "sDatabaseName = sDataBaseDir + '/Hillman.db'\n",
    "conn1 = sq.connect(sDatabaseName)\n",
    "print('DB connected')\n",
    "print('Vault created')\n",
    "sDataVaultDir = Base + '/88-DV'\n",
    "if not os.path.exists(sDataVaultDir):\n",
    "    os.makedirs(sDataVaultDir)\n",
    "\n",
    "sDatabaseName = sDataVaultDir + '/datavault.db'\n",
    "conn2 = sq.connect(sDatabaseName)\n",
    "print('Vault connected')\n",
    "base = datetime(2022, 1, 1, 0, 0, 0)\n",
    "numUnits = 1 * 365 * 24\n",
    "\n",
    "date_list = [base - timedelta(hours=x) for x in range(0, numUnits)]\n",
    "t = 0\n",
    "for i in date_list:\n",
    "    now_utc = i.replace(tzinfo=timezone('UTC'))\n",
    "    sDateTime = now_utc.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    sDateTimeKey = sDateTime.replace(' ', '-').replace(':', '-')\n",
    "    t += 1\n",
    "    IDNumber = str(uuid.uuid4())\n",
    "    t1 = ['UTC'] \n",
    "    t2 = [IDNumber]\n",
    "    t3 = [now_utc]\n",
    "    t4 = [sDateTime]\n",
    "    t5 = [sDateTimeKey]\n",
    "    TimeLine = pd.DataFrame.from_dict(list(zip(t1, t2, t3, t4, t5)))\n",
    "    TimeLine.columns = ['ZoneBaseKey', 'IDNumber', 'nDateTimeValue','DateTimeValue', 'DateTimeKey']\n",
    "    if t == 1:\n",
    "        TimeFrame = pd.DataFrame.from_dict(TimeLine)\n",
    "    else:\n",
    "        TimeRow = pd.DataFrame.from_dict(TimeLine)\n",
    "        TimeFrame = TimeFrame.append(TimeRow)\n",
    "\n",
    "TimeHub = TimeFrame[['IDNumber', 'ZoneBaseKey', 'DateTimeKey', 'DateTimeValue']]\n",
    "TimeHubIndex = TimeHub.set_index(['IDNumber'], inplace=False)\n",
    "\n",
    "TimeFrame.set_index(['IDNumber'], inplace=True)\n",
    "\n",
    "sTable = 'Process-Time'\n",
    "print('Storing :', sDatabaseName, ' Table:', sTable)\n",
    "TimeHubIndex.to_sql(sTable, conn1, if_exists=\"replace\")\n",
    "\n",
    "sTable = 'Hub-Time'\n",
    "print('Storing :', sDatabaseName, ' Table:', sTable)\n",
    "TimeHubIndex.to_sql(sTable, conn2, if_exists=\"replace\")\n",
    "\n",
    "active_timezones = all_timezones\n",
    "z = 0\n",
    "for zone in active_timezones:\n",
    "    t = 0\n",
    "    for j in range(TimeFrame.shape[0]):\n",
    "        now_date = TimeFrame['nDateTimeValue'][j]\n",
    "        DateTimeKey = TimeFrame['DateTimeKey'][j]\n",
    "        now_utc = now_date.replace(tzinfo=timezone('UTC'))\n",
    "        sDateTime = now_utc.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        now_zone = now_utc.astimezone(timezone(zone))\n",
    "        sZoneDateTime = now_zone.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        t += 1\n",
    "        z += 1\n",
    "        IDZoneNumber = str(uuid.uuid4())\n",
    "        tz1 = ['UTC'] \n",
    "        tz2 = [IDZoneNumber]\n",
    "        tz3 = [DateTimeKey]\n",
    "        tz4 = [sDateTime]\n",
    "        tz5 = [sZoneDateTime]\n",
    "        TimeZoneLine = pd.DataFrame.from_dict(list(zip(tz1, tz2, tz3, tz4, tz5)))\n",
    "        TimeZoneLine.columns = ['ZoneBaseKey', 'IDZoneNumber', 'DateTimeKey', 'UTCDateTimeValue', 'DateTimeValue']\n",
    "        if t == 1:\n",
    "            TimeZoneFrame = pd.DataFrame.from_dict(TimeZoneLine)\n",
    "        else:\n",
    "            TimeZoneRow = pd.DataFrame.from_dict(TimeZoneLine)\n",
    "            TimeZoneFrame = TimeZoneFrame.append(TimeZoneRow)\n",
    "    TimeZoneFrameIndex = TimeZoneFrame.set_index(['IDZoneNumber'],\n",
    "                                                 inplace=False)\n",
    "    sZone = zone.replace('/', '-').replace(' ', '')\n",
    "\n",
    "    sTable = 'Process-Time-' + sZone\n",
    "    print('Storing :', sDatabaseName, ' Table:', sTable)\n",
    "    TimeZoneFrameIndex.to_sql(sTable, conn1, if_exists=\"replace\")\n",
    "\n",
    "    sTable = 'Satellite-Time-' + sZone\n",
    "    print('Storing :', sDatabaseName, ' Table:', sTable)\n",
    "    TimeZoneFrameIndex.to_sql(sTable, conn2, if_exists=\"replace\")\n",
    "\n",
    "print('-----------------')\n",
    "print('Vacuum Databases')\n",
    "sSQL = \"VACUUM;\"\n",
    "sql.execute(sSQL, conn1)\n",
    "sql.execute(sSQL, conn2)\n",
    "print('-----------------')\n",
    "print('----------------------------- !! Done!! --------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d0d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\notes\\\\MSc IT\\\\Pract 6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02434cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Vacuum Databases\n",
      "-----------------\n",
      "----------------------------- !! Done!! --------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------')\n",
    "print('Vacuum Databases')\n",
    "print('-----------------')\n",
    "print('----------------------------- !! Done!! --------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c80e030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Working Base : E:\\notes\\MSc IT\\pracs\\Practical 7\n",
      "----------------------------------------\n",
      "----------------------------------------#\n",
      "Time Category\n",
      "UTC Time\n",
      "1960-12-20 10:15:00 (UTC) (+0000)\n",
      "----------------------------------------#\n",
      "Birth Date in Reykjavik :\n",
      "1960-12-20 09:15:00 (-01) (-0100)\n",
      "----------------------------------------#\n",
      "----------------------------------------#\n",
      "Storing : E:\\notes\\MSc IT\\pracs\\Practical 7/99-DW/datawarehouse.db  Table: Hub-Time-Gunnarsson\n",
      "----------------------------------------#\n",
      "----------------------------------------#\n",
      "Storing : E:\\notes\\MSc IT\\pracs\\Practical 7/99-DW/datawarehouse.db  Table: Satellite-Time-Atlantic-Reykjavik-Gunnarsson\n",
      "----------------------------------------#\n",
      "----------------------------------------#\n",
      "Person Category\n",
      "Name: Guðmundur Gunnarsson\n",
      "Birth Date: 1960-12-20 09:15:00\n",
      "Birth Zone: Atlantic/Reykjavik\n",
      "UTC Birth Date: 1960-12-20 10:15:00\n",
      "----------------------------------------#\n",
      "----------------------------------------#\n",
      "Storing : E:\\notes\\MSc IT\\pracs\\Practical 7/99-DW/datawarehouse.db  Table: Hub-Person-Gunnarsson\n",
      "----------------------------------------#\n",
      "#--------------------Done--------------------#\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "import uuid\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "Base = r'E:\\notes\\MSc IT\\pracs\\Practical 7'\n",
    "print('----------------------------------------')\n",
    "print('Working Base :', Base)\n",
    "print('----------------------------------------')\n",
    "\n",
    "InputFileName = 'playstore-analysis.csv'\n",
    "OutputFileName = 'playstore-analysis_updated.csv'\n",
    "Company = 'Valia'\n",
    "\n",
    "sDataBaseDir = Base + '/' + Company + '/04-Transform/SQLite'\n",
    "if not os.path.exists(sDataBaseDir):\n",
    "    os.makedirs(sDataBaseDir)\n",
    "\n",
    "sDatabaseName = sDataBaseDir + '/Vermeulen.db'\n",
    "conn1 = sq.connect(sDatabaseName)\n",
    "\n",
    "sDataVaultDir = Base + '/88-DV'\n",
    "if not os.path.exists(sDataVaultDir):\n",
    "    os.makedirs(sDataVaultDir)\n",
    "\n",
    "sDatabaseName = sDataVaultDir + '/datavault.db'\n",
    "conn2 = sq.connect(sDatabaseName)\n",
    "\n",
    "sDataWarehouseDir = Base + '/99-DW'\n",
    "if not os.path.exists(sDataWarehouseDir):\n",
    "    os.makedirs(sDataWarehouseDir)\n",
    "\n",
    "sDatabaseName = sDataWarehouseDir + '/datawarehouse.db'\n",
    "conn3 = sq.connect(sDatabaseName)\n",
    "\n",
    "print('----------------------------------------#')\n",
    "print('Time Category')\n",
    "print('UTC Time')\n",
    "BirthDateUTC = datetime(1960, 12, 20, 10, 15, 0)\n",
    "BirthDateZoneUTC = BirthDateUTC.replace(tzinfo=timezone('UTC'))\n",
    "BirthDateZoneStr = BirthDateZoneUTC.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "BirthDateZoneUTCStr = BirthDateZoneUTC.strftime(\"%Y-%m-%d %H:%M:%S (%Z) (%z)\")\n",
    "print(BirthDateZoneUTCStr)\n",
    "print('----------------------------------------#')\n",
    "print('Birth Date in Reykjavik :')\n",
    "BirthZone = 'Atlantic/Reykjavik'\n",
    "BirthDate = BirthDateZoneUTC.astimezone(timezone(BirthZone))\n",
    "BirthDateStr = BirthDate.strftime(\"%Y-%m-%d %H:%M:%S (%Z) (%z)\")\n",
    "BirthDateLocal = BirthDate.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(BirthDateStr)\n",
    "print('----------------------------------------#')\n",
    "\n",
    "IDZoneNumber = str(uuid.uuid4())\n",
    "sDateTimeKey = BirthDateZoneStr.replace(' ', '-').replace(':', '-')\n",
    "t1 = ['UTC'] \n",
    "t2 = [IDZoneNumber]\n",
    "t3 = [sDateTimeKey]\n",
    "t4 = [BirthDateZoneUTC]\n",
    "t5 = [BirthZone]\n",
    "t6 = [BirthDateStr]\n",
    "TimeLine = pd.DataFrame.from_dict(list(zip(t1, t2, t3, t4, t5, t6)))\n",
    "TimeLine.columns = ['ZoneBaseKey', 'IDNumber', 'DateTimeKey','UTCDateTimeValue', 'Zone', 'DateTimeValue']\n",
    "TimeFrame = pd.DataFrame.from_dict(TimeLine)\n",
    "\n",
    "TimeHub = TimeFrame[[\n",
    "    'IDNumber', 'ZoneBaseKey', 'DateTimeKey', 'DateTimeValue'\n",
    "]]\n",
    "TimeHubIndex = TimeHub.set_index(['IDNumber'], inplace=False)\n",
    "\n",
    "sTable = 'Hub-Time-Gunnarsson'\n",
    "print('----------------------------------------#')\n",
    "print('Storing :', sDatabaseName, ' Table:', sTable)\n",
    "print('----------------------------------------#')\n",
    "TimeHubIndex.to_sql(sTable, conn2, if_exists=\"replace\")\n",
    "sTable = 'Dim-Time-Gunnarsson'\n",
    "TimeHubIndex.to_sql(sTable, conn3, if_exists=\"replace\")\n",
    "\n",
    "TimeSatellite = TimeFrame[['IDNumber', 'DateTimeKey', 'Zone', 'DateTimeValue']]\n",
    "TimeSatelliteIndex = TimeSatellite.set_index(['IDNumber'], inplace=False)\n",
    "\n",
    "BirthZoneFix = BirthZone.replace(' ', '-').replace('/', '-')\n",
    "sTable = 'Satellite-Time-' + BirthZoneFix + '-Gunnarsson'\n",
    "print('----------------------------------------#')\n",
    "print('Storing :', sDatabaseName, ' Table:', sTable)\n",
    "print('----------------------------------------#')\n",
    "TimeSatelliteIndex.to_sql(sTable, conn2, if_exists=\"replace\")\n",
    "sTable = 'Dim-Time-' + BirthZoneFix + '-Gunnarsson'\n",
    "TimeSatelliteIndex.to_sql(sTable, conn3, if_exists=\"replace\")\n",
    "\n",
    "print('----------------------------------------#')\n",
    "print('Person Category')\n",
    "FirstName = 'Guðmundur'\n",
    "LastName = 'Gunnarsson'\n",
    "print('Name:', FirstName, LastName)\n",
    "print('Birth Date:', BirthDateLocal)\n",
    "print('Birth Zone:', BirthZone)\n",
    "print('UTC Birth Date:', BirthDateZoneStr)\n",
    "print('----------------------------------------#')\n",
    "IDPersonNumber = str(uuid.uuid4())\n",
    "\n",
    "tz1 = [IDPersonNumber]\n",
    "tz2 = [FirstName]\n",
    "tz3 = [LastName]\n",
    "tz4 = ['UTC']\n",
    "tz5 = [BirthDateZoneStr]\n",
    "PersonLine = pd.DataFrame.from_dict(list(zip(tz1, tz2, tz3, tz4, tz5)))\n",
    "PersonLine.columns = ['IDNumber', 'FirstName', 'LastName', 'Zone', 'DateTimeValue']\n",
    "PersonFrame = pd.DataFrame.from_dict(PersonLine)\n",
    "\n",
    "TimeHub = PersonFrame\n",
    "TimeHubIndex = TimeHub.set_index(['IDNumber'], inplace=False)\n",
    "\n",
    "sTable = 'Hub-Person-Gunnarsson'\n",
    "print('----------------------------------------#')\n",
    "print('Storing :', sDatabaseName, ' Table:', sTable)\n",
    "print('----------------------------------------#')\n",
    "TimeHubIndex.to_sql(sTable, conn2, if_exists=\"replace\")\n",
    "sTable = 'Dim-Person-Gunnarsson'\n",
    "TimeHubIndex.to_sql(sTable, conn3, if_exists=\"replace\")\n",
    "print('#--------------------Done--------------------#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717c5947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: pandas>=0.24.2 in e:\\app_data\\conda\\lib\\site-packages (from mlxtend) (1.2.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in e:\\app_data\\conda\\lib\\site-packages (from mlxtend) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in e:\\app_data\\conda\\lib\\site-packages (from mlxtend) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in e:\\app_data\\conda\\lib\\site-packages (from mlxtend) (1.20.1)\n",
      "Requirement already satisfied: setuptools in e:\\app_data\\conda\\lib\\site-packages (from mlxtend) (52.0.0.post20210125)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in e:\\app_data\\conda\\lib\\site-packages (from mlxtend) (0.24.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in e:\\app_data\\conda\\lib\\site-packages (from mlxtend) (3.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\app_data\\conda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\app_data\\conda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\app_data\\conda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\app_data\\conda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in e:\\app_data\\conda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: six in e:\\app_data\\conda\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in e:\\app_data\\conda\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\app_data\\conda\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e031f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Working Base : E:\\notes\\MSc IT\\pracs\\Practical 8  using  win32\n",
      "--------------------------\n",
      "(700, 16)\n",
      "          antecedents         consequents  antecedent support  \\\n",
      "0        (Enterprise)  (Channel Partners)                 1.0   \n",
      "1  (Channel Partners)        (Enterprise)                 1.0   \n",
      "2  (Channel Partners)        (Government)                 1.0   \n",
      "3        (Government)  (Channel Partners)                 1.0   \n",
      "4  (Channel Partners)    (Small Business)                 1.0   \n",
      "\n",
      "   consequent support  support  confidence  lift  leverage  conviction  \n",
      "0                 1.0      1.0         1.0   1.0       0.0         inf  \n",
      "1                 1.0      1.0         1.0   1.0       0.0         inf  \n",
      "2                 1.0      1.0         1.0   1.0       0.0         inf  \n",
      "3                 1.0      1.0         1.0   1.0       0.0         inf  \n",
      "4                 1.0      1.0         1.0   1.0       0.0         inf  \n",
      "Government\n",
      "89080.0\n",
      "Enterprise\n",
      "34902.5\n",
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction]\n",
      "Index: []\n",
      "---------- !!Done!! -----------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "Base = r'E:\\notes\\MSc IT\\pracs\\Practical 8'\n",
    "print('--------------------------')\n",
    "print('Working Base :', Base, ' using ', sys.platform)\n",
    "print('--------------------------')\n",
    "\n",
    "Company = 'Valia'\n",
    "InputFileName = 'Financial Sample.xlsx'\n",
    "EDSAssessDir = '02-Assess/01-EDS'\n",
    "InputAssessDir = EDSAssessDir + '/02-Python'\n",
    "\n",
    "sFileAssessDir = Base + '/' + Company + '/' + InputAssessDir\n",
    "if not os.path.exists(sFileAssessDir):\n",
    "    os.makedirs(sFileAssessDir)\n",
    "\n",
    "sFileName = Base + '/' + InputFileName\n",
    "\n",
    "df = pd.read_excel(sFileName)\n",
    "print(df.shape)\n",
    "\n",
    "df['Segment'] = df['Segment'].str.strip()\n",
    "df.dropna(axis=0, subset=['Country'], inplace=True)\n",
    "df['Country'] = df['Country'].astype('str')\n",
    "df = df[~df['Country'].str.contains('C')]\n",
    "basket = (df[df['Country'] == \"Germany\"].groupby([\n",
    "    'Country', 'Segment'])['Units Sold'].sum().unstack().reset_index().fillna(0).set_index('Country'))\n",
    "\n",
    "\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "\n",
    "basket_sets = basket.applymap(encode_units)\n",
    "basket_sets.drop('Midmarket', inplace=True, axis=1)\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "print(rules.head())\n",
    "rules[(rules['lift'] >= 6) & (rules['confidence'] >= 0.8)]\n",
    "\n",
    "sProduct1 = 'Government'\n",
    "print(sProduct1)\n",
    "print(basket[sProduct1].sum())\n",
    "sProduct2 = 'Enterprise'\n",
    "print(sProduct2)\n",
    "print(basket[sProduct2].sum())\n",
    "\n",
    "basket2 = (df[df['Country'] == \"Germany\"].groupby([\n",
    "    'Country', 'Segment'\n",
    "])['Units Sold'].sum().unstack().reset_index().fillna(0).set_index('Country'))\n",
    "basket_sets2 = basket2.applymap(encode_units)\n",
    "basket_sets2.drop('Small Business', inplace=True, axis=1)\n",
    "frequent_itemsets2 = apriori(basket_sets2, min_support=0.05, use_colnames=True)\n",
    "rules2 = association_rules(frequent_itemsets2, metric=\"lift\", min_threshold=1)\n",
    "print(rules2[(rules2['lift'] >= 4) & (rules2['confidence'] >= 0.5)])\n",
    "\n",
    "print('---------- !!Done!! -----------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031663a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
